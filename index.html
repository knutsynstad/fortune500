<!--Visualizing the Space of Logos of the Fortune 500:
Using machine learning to explore visual similarity in the logos of the Fortune 500.

By Knut M. Synstad
knutsynstad.com
twitter.com/knutsynstad

Source code available on GitHub:
https://github.com/knutsynstad/fortune500
--><!DOCTYPE html><html lang="en"><head><title>Visualizing the Space of Logos of the Fortune 500</title><meta property="og:title" content="Visualizing the Space of Logos of the Fortune 500"><meta property="og:description" content="Using machine learning to explore visual similarity in the logos of the Fortune 500."><meta property="og:image" content="http://fortune500.knutsynstad.com/images/thumbnail.png"><meta property="og:url" content="http://fortune500.knutsynstad.com"><meta property="og:type" content="website"><meta name="twitter:title" content="Visualizing the Space of Logos of the Fortune 500"><meta name="twitter:description" content="Using machine learning to explore visual similarity in the logos of the Fortune 500."><meta name="twitter:image" content="http://fortune500.knutsynstad.com/images/thumbnail.png"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:creator" content="@knutsynstad"><meta property="fb:app_id" content="477243359475813"><meta charset="UTF-8"><meta name="description" content="Using machine learning to explore visual similarity in the logos of the Fortune 500."><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="shortcut icon" href="favicon.ico"><link href="main.css" rel="stylesheet"></head><body data-state="loading" data-overlay="none" data-instructions="false"><svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
	<defs>
		<linearGradient id='gradient'>
			<stop stop-color='black'/>
			<stop offset='100%' stop-color='white'/>
		</linearGradient>
	</defs>
	<symbol id="icon-checkbox" viewBox="0 0 24 24">
		<path d="M19 5v14H5V5h14m0-2H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2z"/>
	</symbol>

	<symbol id="icon-checkbox-checked" viewBox="0 0 24 24">
		<path d="M19 3H5c-1.11 0-2 .9-2 2v14c0 1.1.89 2 2 2h14c1.11 0 2-.9 2-2V5c0-1.1-.89-2-2-2zm-9 14l-5-5 1.41-1.41L10 14.17l7.59-7.59L19 8l-9 9z"/>
	</symbol>

	<symbol id="icon-close" viewBox="0 0 24 24">
		<path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/>
	</symbol>

	<symbol id="icon-edit" viewBox="0 0 24 24">
		<path d="M3 17.25V21h3.75L17.81 9.94l-3.75-3.75L3 17.25zM20.71 7.04c.39-.39.39-1.02 0-1.41l-2.34-2.34c-.39-.39-1.02-.39-1.41 0l-1.83 1.83 3.75 3.75 1.83-1.83z"/>
	</symbol>

	<symbol id="icon-share" viewBox="0 0 24 24">
		<path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81 1.66 0 3-1.34 3-3s-1.34-3-3-3-3 1.34-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9c-1.66 0-3 1.34-3 3s1.34 3 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.16c-.05.21-.08.43-.08.65 0 1.61 1.31 2.92 2.92 2.92 1.61 0 2.92-1.31 2.92-2.92s-1.31-2.92-2.92-2.92z">
	</symbol>

	<symbol id="icon-more" viewBox="0 0 24 24">
		<path d="M12 8c1.1 0 2-.9 2-2s-.9-2-2-2-2 .9-2 2 .9 2 2 2zm0 2c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2zm0 6c-1.1 0-2 .9-2 2s.9 2 2 2 2-.9 2-2-.9-2-2-2z"/>
	</symbol>

	<symbol id="icon-spinner" viewBox="0 0 24 24">
		<path d="M12,19.5v2c-5.238,0-9.5-4.262-9.5-9.5h2C4.5,16.136,7.864,19.5,12,19.5z M19.5,12h2c0-5.238-4.262-9.5-9.5-9.5v2C16.136,4.5,19.5,7.864,19.5,12z"/>
	</symbol>

</svg><div class="wrapper"><section id="introduction"><article><div class="title"><H1>Visualizing the<br />Space of Logos of<br />the Fortune 500</H1></div><h3>Abstract</h3><p>This interactive visualization uses a neural network to analyze a set of logos (in this case the Fortune 500), find similarities and differences, and display the results. Users can adjust the parameters of the display format. The related paper describes how the code works (the analysis and display process). Code is available, enabling others to replicate the process, apply it to their own data sets (other sets of symbols), or to extend it to other uses.</p><h3>Introduction</h3><p>Much of what designers are called upon to do involves looking at how artifacts or features "fit-in" and "stand-out". That is, designers are often concerned with similarity and difference—seeing them, understanding them, and manipulating them. For example, a new icon must fit into a system and also be distinct from it. </p><p>A common step in developing products and identity systems is to collect examples from competitors and discuss them with clients. Now, software can speed up the process, while also enabling inclusion of much larger data sets.</p><p>This example of software development by and for designers—beyond image editing—shows how changes in computing will continue and accelerate changes in design practice. These changes have significant implications for design education and continuing education. For example, it seems clear that designers will need to become comfortable using neural nets to analyze images and t-SNE's to display relationships.</p><p>In this experiment, A.I. techniques are leveraged to algorithmically organize the logos of the Fortune 500 by visual similarity. A task that would be both difficult and time-consuming to do by hand, the computer does with ease. In a nutshell, it's about teaching the computer to see and process patterns. The result is a truly interactive visualization, where the parameters of underlying algorithms have been exposed—enabling viewers to interact with and manipulate the outcome.</p><h3>Background</h3><p>Our own ability to see and process patterns has been essential to our success and survival as a species. The evolution of neural networks in the outer layer of our brains enabled us to process visual and auditory patterns, helping us separate prey from a predator, helpful from harmful—good from bad. In fact, these natural neural networks are so efficient that we’re trying to mimic them with software. However, as the networks grow, so does the time and cost of running them.</p><p>Massachusetts Institute of Technology (MIT) professor in A.I., <a href="http://people.csail.mit.edu/phw/" target="_blank">Patrick Henry Winston</a> calls computing power <a href="http://blogs.discovermagazine.com/crux/2017/10/11/neueral-networks-artificial-intelligence/#.WsAM15PwbOQ" target="_blank">“the most important enabler of <i>deep learning</i> [a type of layered neural network.]”</a> Historically, both cost and access to high-performance computing limited their usefulness. But with the marginal cost of computing dropping to near zero, nearly everyone can now access “affordable” on-demand computing.</p><p>Access to high-performance computing accelerated advancements in A.I., but even the largest networks can’t match the size or complexity of the human brain, yet. That said, artificial neural networks are still able to outperform us on a number of tasks—demonstrating value. In order to understand where to effectively apply them, we must study our own cognitive limitations, so that we can develop solutions that persist where we fall short.</p><p>In his 1956 paper, <a href="http://www.psych.utoronto.ca/users/peterson/psy430s2001/Miller%20GA%20Magical%20Seven%20Psych%20Review%201955.pdf" target="_blank">“The Magical Number Seven, Plus or Minus Two,”</a>, cognitive psychologist George A. Miller discusses our capacity and limitations for processing information. Miller asserted that an average person is able to hold 7 ± 2 pieces of information in their working memory (both immediate memory and absolute judgment) at any given time. His assertion affects our daily life in more than you might think. Ever wonder why U.S. phone numbers and license plates are limited to 7 characters in length?</p><p>Our cognitive limitations make it difficult for us to process large amounts of information. For comparison, our working memory is in the 2–3 bit range, while a 2019 MacBook Pro comes with up to 32 gigabytes or 256,000,000,000 bits of memory—cloud-based systems have orders of magnitude more.</p><p>This experiment takes advantage of computers’ superior working memory and processing speed. The visualization is the result of millions of calculations, and most are calculated right now, in your browser. Doing the calculations in real time enables us to expose the parameters of the underlying algorithms—so you can interact with and manipulate the space of logos.</p><p>The visualization is the outcome of a series of data transformations:</p><ol class="accordion"><li> <div class="accordion-header">Data wrangling<div class="icon"></div></div><div class="accordion-content"><p>Creating a good dataset takes a lot of time and patience. <a href="https://www.nytimes.com/2014/08/18/technology/for-big-data-scientists-hurdle-to-insights-is-janitor-work.html" target="_blank">The New York Times</a> estimated in 2014 that up to 80% of a data scientist’s time is spent collecting and preparing data.</p><p>To get started we simply needed a list of the companies on the Fortune 500 list. Thankfully Fortune Magazine’s robots.txt permits crawling their website for this information, providing the full list and some metadata for each company.</p><p>Collecting the logos took surprisingly long and required a lot of legwork. Striving for consistency, it seemed like a good idea to collect vector versions for all, even though it slowed down the process significantly. Coming from a wide variety of sources, and a wide variety of file formats, it quickly became clear that they needed to be processed, cleaned, and saved in a uniform manner (SVG).</p><figure><svg xmlns="http://www.w3.org/2000/svg" width="73px" height="73px" viewBox="0 0 73 73">
  <g fill="white" opacity="0.5">
    <circle id="illu-1-circle" cx="36.5" cy="36.5" r="36"/>
    <rect id="illu-1-rect1" x="24.5" y="0.5" width="24" height="72"/>
    <rect id="illu-1-rect2" x="0.5" y="24.5" width="72" height="24"/>
  </g>
  <g fill="none" stroke="white">
  	<polyline points="12.5,0.5 0.5,0.5 0.5,12.5"/>
  	<polyline points="72.5,12.5 72.5,0.5 60.5,0.5"/>
  	<polyline points="60.5,72.5 72.5,72.5 72.5,60.5"/>
  	<polyline points="0.5,60.5 0.5,72.5 12.5,72.5"/>
  </g>
</svg>
<figcaption>Fig. 1: Scale to fit</figcaption></figure><p>Using a <a href="https://nodejs.org/en/" target="_blank">NodeJS</a>-powered headless browser (<a href="http://phantomjs.org/" target="_blank">PhantomJS</a>), the vector logos were rendered and exported as bitmap PNGs. Scaled to fit and centered in a 1024 pixel square with a transparent background.</p></div></li><li><div class="accordion-header">Feature detection<div class="icon"></div></div><div class="accordion-content"><p>After collecting the logos they needed to be quantified or measured. What do they look like? What colors are being used? If a designer was to do it by hand they might make note of a number of features such as typography, shape, composition, and color. It’s a time-consuming effort that relies on making subjective decisions that are prone to mistakes and difficult to codify and scale.</p><p>In his 2008 book “<a href="http://danariely.com/books/predictably-irrational/" target="_blank">Predictably Irrational</a>”, <a href="https://twitter.com/danariely" target="_blank">Dan Ariely</a>, professor of Psychology and Behavioral Economics at Duke University asserts: “Humans rarely choose things in absolute terms. We don't have an internal value meter that tells us how much things are worth. Rather, we focus on the relative advantage of one thing over another, and estimate value accordingly.”</p><p>It is more likely that our designer would describe a logo’s features by assigning labels than a numeric value. For example, Walmart has a <i>sans serif</i> typeface while Berkshire Hathaway has a <i>serif</i> typeface. Target’s logo is a <i>circle</i>, while Wells Fargo is a <i>square</i>. One’s familiarity with a domain is proportional with ones the ability to describe objects within it.</p><p>Unlike humans, the computer is more than happy to assign a value. Using a neural network to describe the logos not only provides a list of features but also enumerates to what degree a feature is present or absent. Ensuring a consistent list of features for all logos lets us compare apples with apples. A pre-trained general-purpose image classification network, ResNet50, was used for this process. Developed by a team of <a href="https://arxiv.org/abs/1512.03385" target="_blank">Microsoft researchers</a>, this 50-layer Residual Network won the 2015 ImageNet image classification competition (<a href="http://image-net.org/challenges/LSVRC/2015/" target="_blank">ILSRVS 2015</a>).</p><p>For each logo, the network provided 2048 values. Each representing the presence/absence of a particular feature. Granularly describing the logos across 2048 features/dimensions.</p><p>This is how it described the shape of the Walmart logo:</p><code>0.01971 0.07665 0.10508 0.00000 0.00510 0.48769 0.00000 0.08663 0.09032 0.01971 0.07665 0.10508 0.00000 0.00510 0.48769 0.00000 0.08663 0.09032 0.01971 0.07665 0.10508 0.00000 0.00510 0.48769 0.00000 0.08663 0.09032 …</code><p>When you see this output, it’s easy to understand why many believe the misconception that neural networks are black boxes, with little to no insight into what, how and why it does what it does. Of course, this is simply not true. Unfortunately, what the computer thinks a feature is might not be what our designer believes to be a feature. Naturally, the neural network doesn’t know our semantic structure and cannot recreate it out of the box. Instead, view these features as “feature fragments”, where multiple features are required to form simple shapes such as a circle or a line. </p><p>In addition to shape, it's interesting to look at the usage of color. For each logo, the two most prominent colors were identified and separated by color channel (RGB). This is what Walmart’s top two colors look like:</p><code>-0.00000 124.86442 197.96974 255.00000 194.16913 31.88876</code><p>All in all 2054 features were generated for each logo.</p></div></li><li><div class="accordion-header">Feature selection<div class="icon"></div></div><div class="accordion-content"><p>Not all features the image classifier was trained to spot are relevant for this dataset—many are simply noise. Through a statistical procedure called principal component analysis, the features representing shape was boiled down from 2048 to the 50 most relevant ones.</p><p>A total of 50 shape features and 6 color features formed the basis for our visualization.</p></div></li><li><div class="accordion-header">Distance matrix<div class="icon"></div></div><div class="accordion-content"><p>A list of enumerated features for all logos enables us to calculate the pairwise distance between all pairs. Imagine plotting two logos in a multidimensional chart (one dimension per feature) and drawing a straight line between the two. This line represents the Euclidean distance between the two, a measurement of their similarity or dissimilarity.</p><figure><svg xmlns="http://www.w3.org/2000/svg" width="126px" height="146px" viewBox="0 0 126 146">
	<g fill="none" stroke="white" opacity="0.3">
		<polyline class="st0" points="0.6461,108.9998 62.9996,72.9996 125.3535,108.9996 	"/>
		<line class="st0" x1="63" y1="1.0002" x2="63" y2="73.0003"/>
	</g>
	<line id="illu-2-distance" stroke="white" x1="83.8011" y1="37.0002" x2="21.4282" y2="73"/>
	<g fill="none" stroke="white">
		<polygon class="st2" points="125.3535,37 63,1.0002 0.6461,37.0002 0.6461,108.9998 63,144.9998 125.3539,108.9998"/>
		<line class="st2" x1="63" y1="73.0003" x2="63" y2="144.9998"/>
		<polyline class="st2" points="125.3535,37 63,73.0003 0.6461,37.0002"/>
	</g>
	<g id="illu-2-dots" fill="white">
		<circle cx="21.4282" cy="73" r="3"/>
		<circle cx="83.8011" cy="37.0002" r="3"/>
	</g>
</svg>
<figcaption>Fig. 2: Pairwise distance</figcaption></figure><p>By iterating over all logo pairs, we create a matrix of distances between any two logos.</p></div></li><li><div class="accordion-header">Dimensionality reduction <span class="tag">LIVE</span><div class="icon"></div></div><div class="accordion-content"><p>Since its creation in 2008, Geoffrey Hinton and Laurens van der Maaten’s award-winning t-Distributed Stochastic Neighbor Embedding (t-SNE) algorithm has become incredibly popular. Ideal for creating compelling two-dimensional images of large datasets. The authors have applied it to datasets with up to 30 million nodes.</p><p>It takes a multi-dimensional distance matrix as an input and attempts to plot the data onto a two-dimensional surface while trying to respect the distance between each pair. The solution is incremental and improves with every call of its step function. Adding steps increases the calculation time linearly. The number of steps required to reach a stable structure varies.</p><p>From the t-SNE algorithm, we get a point cloud with x and y values for each logo—ready for plotting. Making it possible to identify patterns of logos sharing one or more features.</p><p>The <a href="https://github.com/karpathy/tsnejs" target="_blank">JavaScript implementation</a> of the algorithm was developed by <a href="https://twitter.com/karpathy" target="_blank">Andrej Karpathy</a>.</p></div></li><li><div class="accordion-header">Linear assignment <span class="tag">LIVE</span><div class="icon"></div></div><div class="accordion-content"><p>The point cloud output of the t-SNE algorithm does not take object size into account for plotting. Similar objects are likely to overlap as there is no collision detection.</p><p>For this reason, the t-SNE algorithm is often paired with an algorithm that aligns the dataset to a grid. A linear assignment algorithm calculates the distance (cost) between each logo and every cell in the grid. Then it assigns one logo per cell, with the goal of achieving the lowest overall cost—minimum distortion of the original point cloud.</p><figure><svg xmlns="http://www.w3.org/2000/svg" width="73" height="73" viewBox="0 0 73 73" >
  <rect fill="none" stroke="white" x="0.5" y="0.5" class="st0" width="72" height="72"/>
  <g id="illu-1-gridlines" fill="none" stroke="white">
    <line x1="24.5" y1="0.5" x2="24.5" y2="72.5"/>
    <line x1="48.5" y1="72.5" x2="48.5" y2="0.5"/>
    <line x1="72.5" y1="24.5" x2="0.5" y2="24.5"/>
    <line x1="0.5" y1="48.5" x2="72.5" y2="48.5"/>
  </g>
  <g fill="white">
    <circle id="illu-dot-1" cx="12.5" cy="12.5" r="3"/>
    <circle id="illu-dot-2" cx="36.5" cy="12.5" r="3"/>
    <circle id="illu-dot-3" cx="60.5" cy="12.5" r="3"/>

    <circle id="illu-dot-4" cx="12.5" cy="36.5" r="3"/>
    <circle id="illu-dot-5" cx="36.5" cy="36.5" r="3"/>
    <circle id="illu-dot-6" cx="60.5" cy="36.5" r="3"/>

    <circle id="illu-dot-7" cx="12.5" cy="60.5" r="3"/>
    <circle id="illu-dot-8" cx="36.5" cy="60.5" r="3"/>
    <circle id="illu-dot-9" cx="60.5" cy="60.5" r="3"/>
  </g>
</svg>
<figcaption>Fig. 3: Linear assignment process</figcaption></figure><p>The <a href="https://github.com/Fil/lap-jv" target="_blank">JavaScript implementation</a> of <a href="https://link.springer.com/article/10.1007/BF02278710" target="_blank">R. Jonker and A. Volgenant’s Linear Assignment Problem algorithm</a> (LAP-JV) was developed by <a href="https://twitter.com/recifs" target="_blank">Philippe Rivière</a>.</p></div></li><li><div class="accordion-header">Data visualization <span class="tag">LIVE</span><div class="icon"></div></div><div class="accordion-content"><p>The final transformation involves plotting the logos in an interactive visualization with <a href="https://d3js.org/" target="_blank">D3.js</a>. In addition to zoom and pan, the visualization dynamically updates as the viewer tunes the parameters of the underlying algorithms.</p><p>By default, JavaScript applications are single thread applications. While running complex calculations, the view may freeze, or even crash—leading to a less than desirable user experience. To avoid this, two web workers were employed to move the bulk of the calculations to two separate CPU threads, enabling the main thread to run uninterrupted.</p></div></li></ol><p>Even though this subject matter is inherently visual, the approach can be applied to anything, as long as it can be measured and quantified.</p><p>I hope you enjoy the experiment. Feel free to <a href="https://twitter.com/knutsynstad" target="_blank">reach out with comments, suggestions, and feedback</a>.</p><p class="em-dash"><a href="http://knutsynstad.com" target="_blank">Knut M. Synstad</a></p></article><div id="entry"><p class="entry-action">Calculating visualization</p><p class="entry-state">Gathering data</p><button id="start">Start exploring</button></div></section></div><svg id="figure"></svg><section id="instructions"><div id="tip"><h3>Instructions</h3><ul><li>Scroll to change zoom level</li><li>Click-and-drag to move (pan)</li><li>Click the edit icon to manipulate</li></ul></div><ul id="tool-highlight"><li>Edit</li><li>Share</li><li>More</li></ul></section><div id="calculating"><div class="icons"><svg class="icon spinner"><use xlink:href="#icon-spinner"></use></svg><svg class="icon cancel"><use xlink:href="#icon-close"></use></svg></div><p class="calculating-label">Calculating visualization</p><p class="calculating-state">Loading data</p></div><div id="overlay"></div><ul class="modal" id="share-modal"><li><a href="https://twitter.com/intent/tweet?url=http%3A%2F%2Ffortune500.knutsynstad.com&amp;text=Visualizing%20the%20Space%20of%20Logos%20of%20the%20Fortune%20500%3A%20Using%20machine%20learning%20to%20explore%20visual%20similarity%20in%20the%20logos%20of%20the%20Fortune%20500.%20%23design%20%23datavisualization%20%23ai" target="_blank">Twitter</a></li><li><a href="https://www.facebook.com/sharer/sharer.php?u=http%3A//fortune500.knutsynstad.com/" target="_blank">Facebook</a></li><li><a href="http://www.linkedin.com/shareArticle?mini=true&amp;url=http%3A%2F%2Ffortune500.knutsynstad.com&amp;title=Visualizing%20the%20Space%20of%20Logos%20of%20the%20Fortune%20500%3A%20Using%20machine%20learning%20to%20explore%20visual%20similarity%20in%20the%20logos%20of%20the%20Fortune%20500.%20%23design%20%23datavisualization%20%23ai" target="_blank">LinkedIn</a></li><li><a href="https://pinterest.com/pin/create/button/?url=http%3A//fortune500.knutsynstad.com&amp;media=http%3A//fortune500.knutsynstad.com/images/thumbnail.png&amp;description=Visualizing%20the%20Space%20of%20Logos%20of%20the%20Fortune%20500%3A%20Using%20machine%20learning%20to%20explore%20visual%20similarity%20in%20the%20logos%20of%20the%20Fortune%20500." target="_blank">Pinterest</a></li><li><a href="mailto:?&amp;subject=Visualizing the Space of Logos of the Fortune 500&amp;body=Visualizing%20the%20Space%20of%20Logos%20of%20the%20Fortune%20500%3A%20Using%20machine%20learning%20to%20explore%20visual%20similarity%20in%20the%20logos%20of%20the%20Fortune%20500.%0A%0Ahttp%3A//fortune500.knutsynstad.com" target="_blank">Email</a></li></ul><ul class="modal" id="more-modal"><li id="introduction-button">Introduction</li><li id="instruction-button">Instructions</li><li><a href="https://github.com/knutsynstad/fortune500" target="_blank">Code</a></li><li id="about-button">About</li></ul><div id="about-modal"><div class="meta"><h3>About</h3><svg class="icon" id="close-about"><use xlink:href="#icon-close"></use></svg></div><div class="primary-column"><p>Using machine learning to discover visual patterns in the logos of the highest earning companies in America, the <a href="http://fortune.com/fortune500/" target="_blank">Fortune 500</a>.</p><p>Visualizations are calculated in real time, enabling viewers to tune the knobs and dials of the underlying algorithms.</p><p>The code is available on <a href="https://github.com/knutsynstad/fortune500" target="_blank">GitHub</a>.</p></div><div class="secondary-column"><h4>Thanks to</h4><ul class="thankyou"><li><a href="http://fortune.com/" target="_blank">Fortune Magazine</a></li><li><a href="https://twitter.com/ryankeisler" target="_blank">Ryan Keisler</a></li><li><a href="https://twitter.com/dubberlydesign" target="_blank">Hugh Dubberly</a></li><li><a href="https://twitter.com/codywackerman" target="_blank">Cody Wackerman</a></li><li><a href="http://www.monicadmiller.com/" target="_blank">Monica Miller</a></li><li><a href="http://www.dubberly.com/" target="_blank">DDO</a></li></ul><h4>Created by</h4><ul><li><a href="https://twitter.com/knutsynstad" target="_blank">Knut M. Synstad</a></li></ul></div></div><div id="configuration-wrapper"><div class="meta"><h3>Configuration</h3><svg class="icon" id="close-configuration"><use xlink:href="#icon-close"></use></svg></div><div class="configuration-scrollable"><ul class="configuration-group"><h4>t-SNE</h4><li><div class="variable"><input id="epsilon" type="number" placeholder="10" value="10" min="1" max="30"><label for="epsilon">Epsilon</label></div><p class="description">Learning rate.</p></li><li><div class="variable"><input id="perplexity" type="number" placeholder="15" value="15" min="1" max="50"><label for="perplexity">Perplexity</label></div><p class="description">A guess about the number of visually similar neighbors each logo has.</p></li><li><div class="variable"><input id="steps" type="number" placeholder="250" value="250" min="1" max="999"><label for="steps">Steps</label></div><p class="description">Solution improves with every step, but the calculation takes longer.</p></li></ul><ul class="configuration-group"><h4>Linear assignment</h4><li><div class="variable"><input id="linearAssignment" type="checkbox" checked><label for="linearAssignment"><span>Enable</span><div class="checkbox"><svg class="icon checked"><use xlink:href="#icon-checkbox-checked"></use></svg><svg class="icon unchecked"><use xlink:href="#icon-checkbox"></use></svg></div></label></div><p class="description">Align to grid.</p></li><li><div class="variable"><input id="cellsPerSide" type="number" placeholder="30" value="30" min="23" max="60"><label for="cellsPerSide">Cells per side</label></div><p class="description">Larger values mean less distortion</p></li><li><div class="variable"><input id="padding" type="number" placeholder="2" value="2" min="0" max="10"><label for="padding">Padding</label></div><p class="description">Space between logos</p></li></ul></div><div class="button-group"><button id="update">Update</button><button id="reset">Reset</button></div></div><nav><h2>Visualizing the<br />Space of Logos of<br />the Fortune 500</h2><ul class="navigation"><li><svg class="icon" id="edit"><use xlink:href="#icon-edit"></use></svg></li><li><svg class="icon" id="share"><use xlink:href="#icon-share"></use></svg></li><li><svg class="icon" id="more"><use xlink:href="#icon-more"></use></svg></li></ul></nav><script src="https://d3js.org/d3.v4.min.js"></script><script async src="https://www.googletagmanager.com/gtag/js?id=UA-43450355-2"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-43450355-2');</script><script type="text/javascript" src="main.js"></script></body></html>